{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srvand/NLP_Transformers/blob/main/Bert_SequenceClassification_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt_AfnVscGDs",
        "outputId": "459ba3de-6d92-4b1b-898e-a7cc406a6826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KrT3HznccvkY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import transformers as trfs\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JJg16tM1c9ol"
      },
      "outputs": [],
      "source": [
        "# Importing Data from file\n",
        "df = pd.read_csv('data.csv').drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8CR5XwqdBo8",
        "outputId": "def48763-cf21-466a-be2f-070f66af9e94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13083, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h0N061LOw4oL",
        "outputId": "6f9cbafb-d40d-4b4a-f338-ec53910f3258"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f572c571-f065-4eab-a178-5450324173cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am still waiting on my card?</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What can I do if my card still hasn't arrived ...</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have been waiting over a week. Is the card s...</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can I track my card while it is in the process...</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do I know if I will get my card, or if it ...</td>\n",
              "      <td>card_arrival</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f572c571-f065-4eab-a178-5450324173cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f572c571-f065-4eab-a178-5450324173cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f572c571-f065-4eab-a178-5450324173cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text      category\n",
              "0                     I am still waiting on my card?  card_arrival\n",
              "1  What can I do if my card still hasn't arrived ...  card_arrival\n",
              "2  I have been waiting over a week. Is the card s...  card_arrival\n",
              "3  Can I track my card while it is in the process...  card_arrival\n",
              "4  How do I know if I will get my card, or if it ...  card_arrival"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding max length of sentence from the data\n",
        "df.text.str.len().max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uxup_4iB24b",
        "outputId": "c22aefc6-ddf0-42fd-9de6-3c39a0257456"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "433"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kAldhNGh0LNt"
      },
      "outputs": [],
      "source": [
        "# Converting Categorical column into Categhory & one hot encoding to feed into model\n",
        "df['category_label']=pd.Categorical(df['category'])\n",
        "df['category']=df['category_label'].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsPmIpxVr61U",
        "outputId": "74339c69-aa51-4db1-b01d-c09a318882a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Unique number of labels\n",
        "df['category'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting hyperparameters for the Model\n",
        "# Max length of encoded string(including special tokens such as [CLS] and [SEP]):\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "# Standard BERT model with lowercase chars only:\n",
        "PRETRAINED_MODEL_NAME = 'bert-base-uncased' \n",
        "# Batch size for fitting:\n",
        "BATCH_SIZE = 64\n",
        "# Number of epochs\n",
        "EPOCHS=5\n",
        "# Setting num of labels\n",
        "num_labels=df['category'].nunique()"
      ],
      "metadata": {
        "id": "Q0H6mEaf6BQG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "# def get_sentence_embeding(sentences):\n",
        "#     preprocessed_text = bert_preprocess(sentences)\n",
        "#     return bert_encoder(preprocessed_text)['pooled_output']"
      ],
      "metadata": {
        "id": "KufMHIMNLTqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load BERT tokenizer\n",
        "tokenizer = trfs.BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "# Load Bert pre-trained model\n",
        "bert_model = trfs.TFBertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME,num_labels=num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtIGiEOAynKh",
        "outputId": "d9b990af-94b9-45a2-f136-bc95008a6272"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model input&attention mask\n",
        "input_ids = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
        "#Model output\n",
        "output = bert_model([input_ids, attention_mask])[0]\n",
        "output = tf.keras.layers.Dense(num_labels, activation='softmax')(output)\n",
        "# Load the Transformers BERT model as a layer in a Keras model(Inputs&Outputs)\n",
        "model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)"
      ],
      "metadata": {
        "id": "WVLMVa536CUF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsbCi2lrzcaE",
        "outputId": "f4580603-ed0a-4ed7-af7a-b48ffcb006fd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_sequence_classific  TFSequenceClassifie  109541453  ['input_ids[0][0]',              \n",
            " ation_2 (TFBertForSequenceClas  rOutput(loss=None,               'attention_mask[0][0]']         \n",
            " sification)                    logits=(None, 77),                                                \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 77)           6006        ['tf_bert_for_sequence_classifica\n",
            "                                                                 tion_2[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,547,459\n",
            "Trainable params: 109,547,459\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set an optimizer\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0PKoe0Bz6our"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the model into Train& Test Data\n",
        "X_train,X_val,Y_train,Y_val = train_test_split(df.text, df.category, test_size=0.2)"
      ],
      "metadata": {
        "id": "rlkKqpDIeJ78"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXOIkuEjeM1n",
        "outputId": "141d06a0-a838-4698-9458-ba1020d08acc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10466,) (2617,) (10466,) (2617,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below step breaks sentences/words into Tokens,add special [CLS]&[SEP]tokens,substitute tokens with ID's\n",
        "def batch_encode(X,tokenizer):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "    X,\n",
        "    max_length=MAX_SEQUENCE_LENGTH, # set the length of the sequences\n",
        "    add_special_tokens=True, # add [CLS] and [SEP] tokens\n",
        "    return_attention_mask=True,\n",
        "    return_token_type_ids=False, # not needed for this type of ML task\n",
        "    pad_to_max_length=True, # add 0 pad tokens to the sequences less than max_length\n",
        "    return_tensors='tf'\n",
        ")\n",
        "# There are few methods for Tokenizer available. Tokenizer,Tokenizer.encode,Tokenizer.encode_plus,Tokenizer.batch_encode_plus\n",
        "#input_ids,toke_type_ids,attention_mask are ouputs of tokenizer\n",
        "# [CLS] token added at first position and [SEP] token added at end of each sentence\n",
        "# In this case we are using batch_encode_plus as sequence of sentences list to be encoded    "
      ],
      "metadata": {
        "id": "lP9REmFXfIqM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_encode(X_train,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sQm6TwbfMom",
        "outputId": "6f613f15-fe4f-47ba-e378-403f9ab8fd8d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(10466, 100), dtype=int32, numpy=\n",
              "array([[ 101, 2129, 2146, ...,    0,    0,    0],\n",
              "       [ 101, 1045, 2347, ...,    0,    0,    0],\n",
              "       [ 101, 2023, 2627, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 101, 2129, 2079, ...,    0,    0,    0],\n",
              "       [ 101, 2339, 2106, ...,    0,    0,    0],\n",
              "       [ 101, 1045, 7039, ...,    0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(10466, 100), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample tokenizer example\n",
        "s1=\"This is a sample sentence\"\n",
        "s2=\"This is second one\"\n",
        "s=[[\"This is a sample sentence\"],[\"This is second one\"]]\n",
        "t=tokenizer(s1,s2)\n",
        "print(t)\n",
        "decoded = tokenizer.decode(t[\"input_ids\"])\n",
        "print(decoded)\n",
        "#input_ids,toke_type_ids,attention_mask are ouputs of tokenizer\n",
        "# [CLS] token added at first position and [SEP] token added at end of each sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBvrFYwNFX6J",
        "outputId": "88f13b18-0aef-44f5-b76a-4374f704afaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2023, 2003, 1037, 7099, 6251, 102, 2023, 2003, 2117, 2028, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[CLS] this is a sample sentence [SEP] this is second one [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t=tokenizer.encode(s1,s2)\n",
        "# print(t)\n",
        "# t=tokenizer.encode_plus(s1)\n",
        "# print(t)\n",
        "# decoded = tokenizer.decode(t[\"input_ids\"])\n",
        "# print(decoded)\n",
        "# t=tokenizer.batch_encode_plus(['This is a sample sentence'], ['This is second one'])\n",
        "# print(t[\"input_ids\"])"
      ],
      "metadata": {
        "id": "kd0rEU4SH2Is"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HtoTLXNef0o",
        "outputId": "06f5a399-5a3f-4d02-9ac2-7f09571dfd66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Encoding the train and test features\n",
        "X_train = batch_encode(X_train,tokenizer)\n",
        "X_val = batch_encode(X_val,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDTnm0fhfwHQ",
        "outputId": "b8e7d2e0-9aa1-43be-814b-783d44e21163"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2617, 100), dtype=int32, numpy=\n",
              "array([[ 101, 1045, 2018, ...,    0,    0,    0],\n",
              "       [ 101, 1045, 2031, ...,    0,    0,    0],\n",
              "       [ 101, 2064, 1045, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 101, 7632,  999, ...,    0,    0,    0],\n",
              "       [ 101, 2129, 2079, ...,    0,    0,    0],\n",
              "       [ 101, 2045, 2003, ...,    0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2617, 100), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMFtsdzagEhd",
        "outputId": "5a990822-e90a-4138-c2d0-8989ff1fb03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "164/164 [==============================] - 422s 2s/step - loss: 3.5857 - accuracy: 0.2208 - val_loss: 2.4043 - val_accuracy: 0.6274\n",
            "Epoch 2/5\n",
            "164/164 [==============================] - 397s 2s/step - loss: 1.6812 - accuracy: 0.7641 - val_loss: 0.9995 - val_accuracy: 0.8624\n",
            "Epoch 3/5\n",
            "164/164 [==============================] - 398s 2s/step - loss: 0.7017 - accuracy: 0.9109 - val_loss: 0.5418 - val_accuracy: 0.9049\n",
            "Epoch 4/5\n",
            "164/164 [==============================] - 397s 2s/step - loss: 0.3336 - accuracy: 0.9549 - val_loss: 0.4029 - val_accuracy: 0.9205\n",
            "Epoch 5/5\n",
            "164/164 [==============================] - 398s 2s/step - loss: 0.1849 - accuracy: 0.9750 - val_loss: 0.3771 - val_accuracy: 0.9194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc90eb16950>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "model.fit(\n",
        "    x=X_train.values(),\n",
        "    y=Y_train,\n",
        "    validation_data=(X_val.values(),Y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clm=model"
      ],
      "metadata": {
        "id": "zzf2jlx_Lg8f"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "# tensorflow.keras.models.save_model(\n",
        "#     model,\n",
        "#    '/model_path/',\n",
        "#     overwrite=True,\n",
        "#     include_optimizer=True,\n",
        "#     save_format=None,\n",
        "#     signatures=None,\n",
        "#     options=None,\n",
        "#     save_traces=True,\n",
        "# )"
      ],
      "metadata": {
        "id": "zWsN9XKnA5x5"
      },
      "execution_count": 78,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Bert_SequenceClassification_V2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}